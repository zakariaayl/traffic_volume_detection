# -*- coding: utf-8 -*-
"""t_v_mf.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1PSR5FIujjj9NKpYChFZA7hhMIYoPGHZy
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
from sklearn.model_selection import train_test_split
from sklearn.feature_selection import SelectFromModel
import joblib

# Load the dataset
df = pd.read_csv('Metro_Interstate_Traffic_Volume.csv')

# Basic data inspection
print("Data shape:", df.shape)
print("\nNull values count:")
print(df.isnull().sum())

# Convert date_time to datetime format
df['date_time'] = pd.to_datetime(df['date_time'])
df.set_index('date_time', inplace=True)

# 1. ENHANCED TIME FEATURES
# Extract basic time components
df['hour'] = df.index.hour
df['day_of_week'] = df.index.dayofweek
df['month'] = df.index.month
df['year'] = df.index.year
df['day_of_month'] = df.index.day
df['week_of_year'] = df.index.isocalendar().week

# Create rush hour flags
df['is_rush_hour_morning'] = df['hour'].between(7, 9).astype(int)
df['is_rush_hour_evening'] = df['hour'].between(16, 19).astype(int)
df['is_rush_hour'] = ((df['is_rush_hour_morning'] == 1) | (df['is_rush_hour_evening'] == 1)).astype(int)

# Weekend flag
df['is_weekend'] = df['day_of_week'].isin([5, 6]).astype(int)

# Time of day category
time_categories = pd.cut(
    df['hour'],
    bins=[0, 6, 11, 14, 19, 24],
    labels=['Night', 'Morning', 'Midday', 'Afternoon', 'Evening']
)
df = pd.concat([df, pd.get_dummies(time_categories, prefix='time_cat')], axis=1)

# Hour of week (0-167, representing each hour in a week)
df['hour_of_week'] = df['day_of_week'] * 24 + df['hour']

# 2. WEATHER FEATURE ENGINEERING
# Convert temperature to Celsius for better interpretability
df['temp_celsius'] = df['temp'] - 273.15

# Weather severity index
df['weather_severity'] = df['clouds_all']/100 + df['rain_1h']*2 + df['snow_1h']*3

# Create combined weather conditions
df['is_precipitation'] = ((df['rain_1h'] > 0) | (df['snow_1h'] > 0)).astype(int)
df['is_heavy_clouds'] = (df['clouds_all'] > 80).astype(int)
df['is_clear_sky'] = (df['clouds_all'] < 20).astype(int)

# Temperature extremes
df['is_freezing'] = (df['temp_celsius'] <= 0).astype(int)
df['is_hot'] = (df['temp_celsius'] >= 30).astype(int)

# Temperature variations (by hour of day)
df['temp_celsius_rolling_mean'] = df.groupby(['hour'])['temp_celsius'].transform(
    lambda x: x.rolling(7, min_periods=1).mean()
)
df['temp_celsius_diff'] = df.groupby(['hour'])['temp_celsius'].diff().fillna(0)

# 3. HOLIDAY AND SPECIAL DAYS ENHANCEMENT
# Fill NaN values in holiday column
df['holiday'] = df['holiday'].fillna('None')

# Create binary holiday indicator
df['is_holiday'] = (df['holiday'] != 'None').astype(int)

# Day before/after holiday
df['day_before_holiday'] = df.groupby(df.index.date)['is_holiday'].shift(-1).fillna(0).astype(int)
df['day_after_holiday'] = df.groupby(df.index.date)['is_holiday'].shift(1).fillna(0).astype(int)

# Create seasonal holidays flag
def is_seasonal_holiday(date):
    month = date.month
    day = date.day
    # Check for major holiday periods
    if (month == 12 and day >= 20) or (month == 1 and day <= 3):  # Christmas/New Year
        return 1
    elif (month == 11 and day >= 22) and (month == 11 and day <= 30):  # Thanksgiving
        return 1
    # Add more seasonal holidays as needed
    return 0

df['is_seasonal_holiday'] = df.index.map(is_seasonal_holiday)

# 4. ADVANCED TIME SERIES FEATURES
# Create lag features at different intervals
for lag in [1, 2, 3, 24, 24*7]:  # 1h, 2h, 3h, 1 day, 1 week
    df[f'traffic_volume_lag_{lag}'] = df['traffic_volume'].shift(lag)

# Create rolling statistics
for window in [3, 6, 12, 24]:
    df[f'rolling_mean_{window}h'] = df['traffic_volume'].rolling(window=window).mean()
    df[f'rolling_std_{window}h'] = df['traffic_volume'].rolling(window=window).std()

# Create features for same hour on previous days
df['traffic_yesterday_same_hour'] = df['traffic_volume'].shift(24)
df['traffic_week_ago_same_hour'] = df['traffic_volume'].shift(24*7)

# Normalize by typical traffic for that day/hour
hour_of_week_means = df.groupby('hour_of_week')['traffic_volume'].transform('mean')
df['traffic_vs_typical'] = df['traffic_volume'] / hour_of_week_means

# 5. WEATHER-TIME INTERACTION FEATURES
# Create interaction features between weather and time
df['rain_during_rush_hour'] = df['rain_1h'] * df['is_rush_hour']
df['snow_during_rush_hour'] = df['snow_1h'] * df['is_rush_hour']
df['bad_weather_weekend'] = df['is_weekend'] * df['weather_severity']

# Season-based features
season_map = {1: 'Winter', 2: 'Winter', 3: 'Spring', 4: 'Spring', 5: 'Spring',
              6: 'Summer', 7: 'Summer', 8: 'Summer', 9: 'Fall', 10: 'Fall',
              11: 'Fall', 12: 'Winter'}
df['season'] = df['month'].map(season_map)

# Create season dummies
df = pd.concat([df, pd.get_dummies(df['season'], prefix='season')], axis=1)

# Adverse weather conditions by season
df['is_adverse_season_weather'] = (
    ((df['season'] == 'Winter') & ((df['temp_celsius'] < 0) | (df['snow_1h'] > 0))) |
    ((df['season'] == 'Summer') & (df['temp_celsius'] > 30))
).astype(int)

# 6. HANDLE CATEGORICAL VARIABLES
# One-hot encode weather_main and weather_description
df = pd.get_dummies(df, columns=['weather_main', 'weather_description'], drop_first=False)

# Drop the original holiday column and keep only the engineered features
df.drop(['holiday', 'season'], axis=1, inplace=True)

# 7. HANDLE MISSING VALUES
# Fill missing values created by lag features
numerical_cols = df.select_dtypes(include=[np.number]).columns
df[numerical_cols] = df[numerical_cols].fillna(df[numerical_cols].median())

# Print info about the engineered dataset
print("\nEngineered dataset shape:", df.shape)
print("\nEngineered features:", [col for col in df.columns if col != 'traffic_volume'])

# Split the data into features and target
X = df.drop('traffic_volume', axis=1)
max_volume = df['traffic_volume'].max()
y = df['traffic_volume'] / max_volume  # Scale target

# Split the data into training and testing sets (time-series split)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, shuffle=False)

# 8. FEATURE SELECTION
# Use RandomForest to select important features
print("\nPerforming feature selection...")
selector = SelectFromModel(RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1), threshold='median')
selector.fit(X_train, y_train)

# Get selected features
selected_features = X_train.columns[selector.get_support()]
print(f"\nSelected {len(selected_features)} out of {X_train.shape[1]} features:")
print(selected_features.tolist())

# Use only selected features
X_train_selected = X_train[selected_features]
X_test_selected = X_test[selected_features]

# 9. MODEL TRAINING WITH SELECTED FEATURES
print("\nTraining model with selected features...")
model = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1)
model.fit(X_train_selected, y_train)

# Save the model and the feature selector
joblib.dump(model, 'traffic_volume_enhanced_model.joblib')
joblib.dump(selector, 'traffic_volume_feature_selector.joblib')

# 10. MODEL EVALUATION
# Predict and evaluate the model
y_pred = model.predict(X_test_selected)
mae = mean_absolute_error(y_test, y_pred)
mse = mean_squared_error(y_test, y_pred)
rmse = np.sqrt(mse)
r2 = r2_score(y_test, y_pred)
accuracy = r2 * 100

# Print evaluation metrics
print(f"\nModel Evaluation Metrics:")
print(f"Mean Absolute Error: {mae}")
print(f"Mean Squared Error: {mse}")
print(f"Root Mean Squared Error: {rmse}")
print(f"RÂ² Score: {r2}")
print(f"Accuracy (%): {accuracy}")

# 11. FEATURE IMPORTANCE ANALYSIS
# Get feature importances
feature_importances = pd.DataFrame({
    'feature': selected_features,
    'importance': model.feature_importances_
}).sort_values('importance', ascending=False)

print("\nTop 20 Most Important Features:")
print(feature_importances.head(20))

# 12. VISUALIZE RESULTS
# Plot the actual vs. predicted traffic volume
plt.figure(figsize=(15, 6))
plt.plot(y_test.index, y_test * max_volume, label='Actual')
plt.plot(y_test.index, y_pred * max_volume, label='Predicted')
plt.legend()
plt.title('Actual vs Predicted Traffic Volume')
plt.xlabel('Date Time')
plt.ylabel('Traffic Volume')
plt.tight_layout()
plt.savefig('actual_vs_predicted.png')
plt.close()

# Plot feature importance
plt.figure(figsize=(12, 10))
feature_importances.head(20).plot.barh(x='feature', y='importance')
plt.title('Top 20 Feature Importance')
plt.tight_layout()
plt.savefig('feature_importance.png')
plt.close()

# 13. PREDICTION FUNCTION
def predict_traffic(input_data, road_km=12.87, road_width=0.0355):
    """
    Predict traffic volume for new data and adjust for road characteristics.

    Args:
        input_data (dict or pd.DataFrame): Input data with feature values
        road_km (float): Length of the road in kilometers
        road_width (float): Width of the road in kilometers

    Returns:
        float: Predicted traffic volume adjusted for road characteristics
    """
    # Convert input data to DataFrame if it's a dictionary
    if isinstance(input_data, dict):
        # Create DataFrame with all required columns in the correct order
        input_df = pd.DataFrame([input_data])[X_train.columns]
    else:
        input_df = input_data

    # Apply feature selector to use only selected features
    input_selected = input_df[selected_features]

    # Make prediction
    prediction = model.predict(input_selected)[0] * max_volume

    # Adjust prediction based on road characteristics
    distance_ratio = road_km / 12.87
    width_ratio = road_width / 0.0355
    adjustment_factor = distance_ratio * width_ratio
    adjusted_prediction = prediction * adjustment_factor

    return prediction, adjusted_prediction

# 14. EXAMPLE USAGE
print("\nExample Prediction:")

# Create a sample input with ALL features that were in the training data
def generate_complete_sample_input(X_train_columns):
    """
    Generate a sample input dictionary with all the required features
    """
    # Start with base features
    sample_input = {
        'temp': 285.32,
        'rain_1h': 0.0,
        'snow_1h': 0.0,
        'clouds_all': 75,
        'hour': 14,
        'day_of_week': 2,
        'month': 8,
        'year': 2023,
        'day_of_month': 1,
        'week_of_year': 32,  # Adding the missing feature
        'is_rush_hour_morning': 0,
        'is_rush_hour_evening': 0,
        'is_rush_hour': 0,
        'is_weekend': 0,
        'hour_of_week': 14 + 2*24,  # Tuesday 2PM
        'temp_celsius': 285.32 - 273.15,
        'temp_celsius_rolling_mean': 12.5,  # Adding the missing feature
        'temp_celsius_diff': 0.2,  # Adding the missing feature
        'weather_severity': 75/100,
        'is_precipitation': 0,
        'is_heavy_clouds': 0,
        'is_clear_sky': 0,
        'is_freezing': 0,
        'is_hot': 0,
        'is_holiday': 0,
        'day_before_holiday': 0,
        'day_after_holiday': 0,
        'is_seasonal_holiday': 0,
        'traffic_volume_lag_1': 1800.0,
        'traffic_volume_lag_2': 1700.0,
        'traffic_volume_lag_3': 1600.0,
        'traffic_volume_lag_24': 1900.0,
        'traffic_volume_lag_168': 1850.0,
        'rolling_mean_3h': 1700.0,
        'rolling_mean_6h': 1750.0,
        'rolling_mean_12h': 1800.0,
        'rolling_mean_24h': 1850.0,
        'rolling_std_3h': 100.0,
        'rolling_std_6h': 120.0,
        'rolling_std_12h': 150.0,
        'rolling_std_24h': 200.0,
        'traffic_yesterday_same_hour': 1900.0,
        'traffic_week_ago_same_hour': 1850.0,
        'traffic_vs_typical': 1.05,
        'rain_during_rush_hour': 0.0,
        'snow_during_rush_hour': 0.0,
        'bad_weather_weekend': 0.0,
        'is_adverse_season_weather': 0
    }

    # Ensure all columns from training data are included
    for col in X_train.columns:
        if col not in sample_input:
            # For categorical/dummy variables, set to 0 by default
            sample_input[col] = 0

    # Set specific categories to 1
    sample_input['weather_main_Clouds'] = 1
    sample_input['weather_description_broken clouds'] = 1
    sample_input['time_cat_Afternoon'] = 1
    sample_input['season_Summer'] = 1

    return sample_input

# Get a complete sample input with all features
sample_input = generate_complete_sample_input(X_train.columns)

# Verify that all required features are present
missing_features = set(X_train.columns) - set(sample_input.keys())
if missing_features:
    print(f"Warning: Missing features: {missing_features}")
    for feature in missing_features:
        sample_input[feature] = 0  # Default value for missing features

# Ensure we're only using features that were in the training data
extra_features = set(sample_input.keys()) - set(X_train.columns)
if extra_features:
    print(f"Warning: Extra features found: {extra_features}")
    for feature in extra_features:
        del sample_input[feature]

# Create a DataFrame with the sample input in the correct order
sample_df = pd.DataFrame([sample_input])[X_train.columns]

# Make prediction using the sample DataFrame with the correct feature order
highway_prediction, my_road_prediction = predict_traffic(
    sample_df,
    road_km=10,
    road_width=0.01
)

print(f"Predicted Highway Traffic Volume: {highway_prediction:.2f}")
print(f"Adjusted Traffic Volume for Custom Road: {my_road_prediction:.2f}")

print("\nComplete! Enhanced traffic volume prediction model with feature engineering is ready.")

"""## Key Differences Between the Two Traffic Volume Prediction Code Files / File 1 : Othmane, File 2 : Zakariae

### 1. Complexity and Feature Engineering
- **First file**: Much more comprehensive feature engineering with advanced time features, weather features, and interaction features
- **Second file**: Simpler approach with basic feature engineering (time components, one-hot encoding)

### 2. Feature Set
- **First file**: Creates 100+ features including:
  - Enhanced time features (rush hour flags, time categories, hour of week)
  - Weather severity indices and combinations
  - Holiday enrichment (day before/after holiday)
  - Time series features (multiple lag periods, rolling statistics)
  - Weather-time interactions
  - Seasonal analysis

- **Second file**: Creates ~50 features including:
  - Basic time components (hour, day_of_week, month)
  - Simple one-hot encoding for weather
  - Only two lag features

### 3. Data Preprocessing
- **First file**:
  - More sophisticated handling of missing values
  - Feature selection to reduce dimensionality
  - Target scaling (divide by max volume)
  
- **Second file**:
  - Simpler approach to handling missing values
  - No feature selection
  - Also scales target but with less preprocessing

### 4. Model Development
- **First file**:
  - Uses feature selection with SelectFromModel
  - Trained on selected features only
  - More comprehensive model evaluation
  
- **Second file**:
  - Uses all available features
  - No feature selection
  - Basic model evaluation

### 5. Visualization and Analysis
- **First file**: Creates saved visualizations for actual vs. predicted and feature importance
- **Second file**: Shows plots but doesn't save them

### 6. Prediction Function
- **First file**: More extensive prediction function with additional road parameters
- **Second file**: Simpler adjustment function but similar road parameter considerations

### 7. Code Structure and Documentation
- **First file**: Better organized with numbered sections and more extensive comments
- **Second file**: More exploratory in nature, appears to be from a Jupyter notebook

### 8. Use Case
- **First file**: Production-ready approach with feature selection and model saving
- **Second file**: More experimental/exploratory analysis approach
"""